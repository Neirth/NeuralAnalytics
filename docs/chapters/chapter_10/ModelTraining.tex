\chapter{Entrenamiento del modelo}\label{ch:model_training}

Tras completar el desarrollo de la arquitectura del sistema, se procedió al entrenamiento del modelo para la clasificación de señales EEG. Esta fase representó un hito crítico del proyecto, donde se validarían los fundamentos teóricos y la viabilidad práctica de la aproximación propuesta.

Este capítulo documenta de manera sistemática el proceso de entrenamiento del modelo, incluyendo las decisiones arquitectónicas, metodología experimental y resultados obtenidos. El desarrollo de esta fase presentó diversos desafíos técnicos que requirieron adaptaciones iterativas en la aproximación inicial.

\section{Descripción de la arquitectura}

La selección de la arquitectura neuronal constituyó una decisión técnica fundamental del proyecto. Se optó por una arquitectura híbrida que combina redes LSTM (Long Short-Term Memory) con capas densas, fundamentada en la capacidad demostrada de las LSTM para procesar secuencias temporales complejas como las señales EEG. 

El sistema se diseñó para procesar y clasificar secuencias temporales de datos neurofisiológicos, utilizando ventanas de 62 puntos temporales como entrada base.

\subsection{Estructura de la red neuronal}

Se implementó una arquitectura híbrida específicamente diseñada para procesar señales EEG de los cuatro canales seleccionados: T3, T4, O1 y O2. El sistema realiza clasificación en tres categorías: RED, GREEN y TRASH, manteniendo un enfoque simplificado que facilita la validación inicial del concepto.

La arquitectura final se estableció tras un proceso iterativo de experimentación con diferentes configuraciones de capas y parámetros de red.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.35\textwidth]{assets/figures/neural_analytics.onnx.png}
    \caption{Arquitectura del modelo de clasificación de señales EEG}
    \label{fig:model_architecture}
\end{figure}

Los componentes principales son:

\begin{itemize}
    \item \textbf{Capa LSTM}: Una capa LSTM con 64 unidades que captura patrones temporales en las señales. La configuración utiliza \texttt{batch\_first=True} para optimizar la forma de entrada (batch\_size, seq\_length, features).
    
    \item \textbf{Capas densas}: Después de la LSTM, hay varias capas:
    \begin{itemize}
        \item Primera capa densa: Reduce de 64 a 32 unidades.
        \item Activación ReLU: Añade no-linealidad.
        \item Segunda capa densa: Proyecta a 3 neuronas de salida.
        \item Softmax: Normaliza las salidas como probabilidades.
    \end{itemize}
\end{itemize}

El flujo de datos es así:

\begin{enumerate}
    \item Entra una secuencia de 62 puntos, cada uno con 4 características.
    \item La LSTM procesa esto y saca 64 características por punto.
    \item Se toma el último estado de la secuencia.
    \item Este pasa por las capas densas con ReLU.
    \item La capa final con Softmax da la probabilidad para cada clase.
\end{enumerate}

\subsection{Parámetros del modelo}

Los principales parámetros son:

\begin{itemize}
    \item \texttt{INPUT\_SIZE = 4}: Los cuatro canales.
    \item \texttt{HIDDEN\_SIZE = 64}: Unidades en la capa LSTM.
    \item \texttt{NUM\_CLASSES = 3}: Las tres categorías.
    \item \texttt{WINDOW\_SIZE = 62}: Tamaño de ventana para secuencias.
    \item \texttt{BATCH\_SIZE = 64}: Muestras por lote en entrenamiento.
\end{itemize}

\section{Preprocesamiento de los datos}

El preprocesamiento constituye una fase crítica para garantizar la calidad de las entradas al modelo. Se implementaron múltiples etapas de procesamiento, desde la captura inicial hasta la generación de ventanas deslizantes optimizadas.

\subsection{Adquisición y estructuración del dataset}

El dataset tiene esta estructura:

\begin{itemize}
    \item \textbf{Organización por clases}: Archivos CSV en directorios según clase:
    \begin{itemize}
        \item \texttt{/red/}: Datos mientras el usuario piensa en rojo.
        \item \texttt{/green/}: Datos mientras piensa en verde.
        \item \texttt{/trash/}: Datos que no encajan en lo anterior.
    \end{itemize}
    
    \item \textbf{Formato}: Cada CSV tiene mediciones de T3, T4, O1 y O2 en columnas.
\end{itemize}

\subsection{Etapas de preprocesamiento}

El proceso está en la función \texttt{neural\_analytics\_preprocessor} y hace:

\begin{enumerate}
    \item \textbf{Normalización}: Escala los canales EEG al rango [0,1].
    
    \item \textbf{Extracción de etiquetas}: Saca la clase del nombre del directorio.
    
    \item \textbf{Codificación one-hot}: Convierte etiquetas a vectores:
    \begin{itemize}
        \item \texttt{red}: [1, 0, 0]
        \item \texttt{green}: [0, 1, 0]
        \item \texttt{trash}: [0, 0, 1]
    \end{itemize}
    
    \item \textbf{Ventanas deslizantes}: Para cada CSV, crea ventanas con solapamiento.
\end{enumerate}

\subsection{Implementación del dataset}

Se desarrolló una clase \texttt{NeuralAnalyticsDataset} que hereda de \texttt{Dataset} de PyTorch. Esta implementación:

\begin{itemize}
    \item Recorre el directorio y procesa los CSV.
    \item Aplica el preprocesamiento.
    \item Guarda ventanas y etiquetas.
    \item Convierte a tensores de PyTorch.
    \item Implementa \texttt{\_\_len\_\_} y \texttt{\_\_getitem\_\_}.
\end{itemize}

Durante la inicialización, se implementa división automática en conjuntos de entrenamiento (80\%) y validación (20\%) utilizando \texttt{train\_test\_split}.

\section{Resultados del entrenamiento}

Se utilizó PyTorch como framework de entrenamiento debido a su flexibilidad y rendimiento optimizado. Los resultados obtenidos se detallan a continuación.

\subsection{Configuración del entrenamiento}

Se estableció la siguiente configuración para el proceso de entrenamiento:

\begin{itemize}
    \item \textbf{Función de pérdida}: \texttt{CrossEntropyLoss}.
    
    \item \textbf{Optimizador}: Adam con tasa inicial 0.001.
    
    \item \textbf{Planificador}: \texttt{ReduceLROnPlateau} que reduce la tasa si la pérdida se estanca.
    
    \item \textbf{Épocas}: 1000, con evaluaciones periódicas.
    
    \item \textbf{Monitorización}: TensorBoard para ver métricas en tiempo real.
\end{itemize}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/loss_vs_epochs.png}
        \caption{Evolución de la pérdida durante el entrenamiento}
        \label{fig:loss_vs_epochs}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/accuracy_vs_epochs.png}
        \caption{Evolución de la precisión durante el entrenamiento}
        \label{fig:accuracy_vs_epochs}
    \end{subfigure}
    \caption{Curvas de entrenamiento del modelo Neural Analytics}
    \label{fig:training_curves}
\end{figure}

\newpage
\subsection{Métricas de rendimiento}

Las métricas de rendimiento obtenidas son las siguientes:

\begin{itemize}
    \item \textbf{Precisión}: 84.3\% en validación, resultado satisfactorio para el objetivo del proyecto.
    
    \item \textbf{Matriz de confusión}: Los resultados muestran mayor confusión entre las clases \texttt{red} y \texttt{trash} comparado con \texttt{green}.
    
    \item \textbf{Curvas ROC}: Se obtuvieron valores AUC superiores a 0.95 para todas las clases, indicando excelente poder discriminativo del modelo.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/figures/confusion_matrix.png}
    \caption{Matriz de confusión del modelo en el conjunto de validación}
    \label{fig:confusion_matrix}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_RED.png}
        \caption{Curva ROC para la clase \texttt{RED}}
        \label{fig:roc_red}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_GREEN.png}
        \caption{Curva ROC para la clase \texttt{GREEN}}
        \label{fig:roc_green}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_TRASH.png}
        \caption{Curva ROC para la clase \texttt{TRASH}}
        \label{fig:roc_trash}
    \end{subfigure}
    \caption{Curvas ROC para cada una de las clases}
    \label{fig:roc_curves}
\end{figure}


\newpage
\subsection{Análisis de resultados}

El análisis de los resultados revela los siguientes hallazgos:

\begin{itemize}
    \item La arquitectura LSTM demuestra capacidad efectiva para capturar patrones relevantes en las señales EEG.
    
    \item El refinamiento realizado en abril 2025 produjo mejoras significativas, incrementando la precisión del 55\% inicial a más del 84\% mediante la ampliación del dataset.
    
    \item Las clases RED y GREEN presentan patrones más distinguibles, mientras que TRASH muestra mayor variabilidad inherente.
    
    \item La variabilidad en los procesos cognitivos de visualización de colores entre usuarios constituye un factor relevante que requiere protocolos estandarizados para la captura de datos.
\end{itemize}

\subsection{Exportación del modelo}

Completado el entrenamiento, se procedió a la exportación del modelo al formato ONNX para su integración en el proyecto desarrollado en Rust. El proceso implementado incluye:

\begin{itemize}
    \item Convertir de PyTorch a ONNX con \texttt{torch.onnx.export}.
    \item Especificar ejes dinámicos para lotes variables.
    \item Optimizar con plegado de constantes.
    \item Guardar en \texttt{build/neural\_analytics.onnx}.
\end{itemize}

Esta configuración permite la utilización del modelo mediante \texttt{tract-onnx} en el servicio de inferencia, manteniendo el rendimiento alcanzado durante el entrenamiento.
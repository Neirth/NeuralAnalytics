\chapter{Entrenamiento del modelo}\label{ch:model_training}

Tras definir el cronograma de este trabajo, se procedió al entrenamiento del modelo para la clasificación de señales EEG. Esta fase representó un hito de alta relevancia para el proyecto, donde se validarían los fundamentos teóricos y la viabilidad práctica de la aproximación propuesta.

Este capítulo documenta de manera sistemática el proceso de entrenamiento del modelo, incluyendo las decisiones arquitectónicas, la metodología experimental y los resultados obtenidos. El desarrollo de esta fase presentó diversos desafíos técnicos que requirieron adaptaciones iterativas en la aproximación inicial.

\section{Descripción de la arquitectura}

La selección de la arquitectura neuronal constituyó una decisión técnica fundamental del proyecto. Se optó por una arquitectura híbrida que combina redes LSTM (Long Short-Term Memory) con capas densas, elección fundamentada en la capacidad demostrada de las LSTM para procesar secuencias temporales complejas como las señales EEG.

El sistema se diseñó para procesar y clasificar secuencias temporales de datos neurofisiológicos, utilizando ventanas de 62 puntos temporales como entrada base.

\subsection{Estructura de la red neuronal}

Se implementó una arquitectura híbrida específicamente diseñada para procesar señales EEG de los cuatro canales seleccionados: T3, T4, O1 y O2. El sistema realiza una clasificación en tres categorías: RED, GREEN y TRASH, manteniendo un enfoque simplificado que facilita la validación inicial del concepto.

La arquitectura final se estableció tras un proceso iterativo de experimentación con diferentes configuraciones de capas y parámetros de red.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.35\textwidth]{assets/figures/neural_analytics.onnx.png}
    \caption{Arquitectura del modelo de clasificación de señales EEG}
    \label{fig:model_architecture}
\end{figure}

Los componentes principales son:

\begin{itemize}
    \item \textbf{Capa LSTM}: Una capa LSTM con 64 unidades que captura patrones temporales en las señales. La configuración utiliza \texttt{batch\_first=True} para optimizar la forma de entrada (batch\_size, seq\_length, features).
    
    \item \textbf{Capas densas}: Después de la LSTM, se encuentran varias capas:
    \begin{itemize}
        \item Primera capa densa: Reduce de 64 a 32 unidades.
        \item Activación ReLU: Añade no-linealidad.
        \item Segunda capa densa: Proyecta a 3 neuronas de salida.
        \item Softmax: Normaliza las salidas como probabilidades.
    \end{itemize}
\end{itemize}

El flujo de datos se describe a continuación:

\begin{enumerate}
    \item Ingresa una secuencia de 62 puntos, cada uno con 4 características.
    \item La LSTM procesa esta secuencia y extrae 64 características por punto.
    \item Se toma el último estado de la secuencia.
    \item Este estado atraviesa las capas densas con activación ReLU.
    \item La capa final con Softmax proporciona la probabilidad para cada clase.
\end{enumerate}

\subsection{Parámetros del modelo}

Los principales parámetros son:

\begin{itemize}
    \item \texttt{INPUT\_SIZE = 4}: Corresponde a los cuatro canales.
    \item \texttt{HIDDEN\_SIZE = 64}: Unidades en la capa LSTM.
    \item \texttt{NUM\_CLASSES = 3}: Las tres categorías de clasificación.
    \item \texttt{WINDOW\_SIZE = 62}: Tamaño de la ventana para las secuencias.
    \item \texttt{BATCH\_SIZE = 64}: Número de muestras por lote durante el entrenamiento.
\end{itemize}

\section{Preprocesamiento de los datos}

El preprocesamiento constituye una fase crítica para garantizar la calidad de las entradas al modelo. Se implementaron múltiples etapas de procesamiento, desde la captura inicial hasta la generación de ventanas deslizantes optimizadas.

\subsection{Adquisición y estructuración del dataset}

El dataset presenta la siguiente estructura:

\begin{itemize}
    \item \textbf{Organización por clases}: Archivos CSV almacenados en directorios según la clase:
    \begin{itemize}
        \item \texttt{/red/}: Datos registrados mientras el usuario piensa en el color rojo.
        \item \texttt{/green/}: Datos registrados mientras el usuario piensa en el color verde.
        \item \texttt{/trash/}: Datos que no se corresponden con las categorías anteriores.
    \end{itemize}
    
    \item \textbf{Formato}: Cada archivo CSV contiene mediciones de los canales T3, T4, O1 y O2 en columnas.
\end{itemize}

\subsection{Etapas de preprocesamiento}

El proceso se encuentra encapsulado en la función \texttt{neural\_analytics\_preprocessor} y realiza las siguientes operaciones:

\begin{enumerate}
    \item \textbf{Normalización}: Escala los canales EEG al rango [0,1].
    
    \item \textbf{Extracción de etiquetas}: Obtiene la clase a partir del nombre del directorio.
    
    \item \textbf{Codificación one-hot}: Convierte las etiquetas categóricas a vectores binarios:
    \begin{itemize}
        \item \texttt{red}: [1, 0, 0]
        \item \texttt{green}: [0, 1, 0]
        \item \texttt{trash}: [0, 0, 1]
    \end{itemize}
    
    \item \textbf{Ventanas deslizantes}: Para cada archivo CSV, crea ventanas con solapamiento.
\end{enumerate}

\subsection{Implementación del dataset}

Se desarrolló una clase \texttt{NeuralAnalyticsDataset} que hereda de \texttt{Dataset}, propia de PyTorch. Esta implementación:

\begin{itemize}
    \item Recorre el directorio y procesa los archivos CSV.
    \item Aplica el preprocesamiento definido.
    \item Almacena las ventanas y sus etiquetas correspondientes.
    \item Convierte los datos a tensores de PyTorch.
    \item Implementa los métodos \texttt{\_\_len\_\_} y \texttt{\_\_getitem\_\_}.
\end{itemize}

Durante la inicialización, se implementa una división automática en conjuntos de entrenamiento (80\%) y validación (20\%) utilizando la función \texttt{train\_test\_split}.

\section{Resultados del entrenamiento}

Se utilizó PyTorch como framework de entrenamiento debido a su flexibilidad y rendimiento optimizado. Los resultados obtenidos se detallan a continuación.

\subsection{Configuración del entrenamiento}

Se estableció la siguiente configuración para el proceso de entrenamiento:

\begin{itemize}
    \item \textbf{Función de pérdida}: \texttt{CrossEntropyLoss}.
    
    \item \textbf{Optimizador}: Adam con una tasa de aprendizaje inicial de 0.001.
    
    \item \textbf{Planificador}: \texttt{ReduceLROnPlateau}, que reduce la tasa de aprendizaje si la pérdida se estanca.
    
    \item \textbf{Épocas}: 1000, con evaluaciones periódicas del rendimiento.
    
    \item \textbf{Monitorización}: TensorBoard para la visualización de métricas en tiempo real.
\end{itemize}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/loss_vs_epochs.png}
        \caption{Evolución de la pérdida durante el entrenamiento}
        \label{fig:loss_vs_epochs}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/accuracy_vs_epochs.png}
        \caption{Evolución de la precisión durante el entrenamiento}
        \label{fig:accuracy_vs_epochs}
    \end{subfigure}
    \caption{Curvas de entrenamiento del modelo Neural Analytics}
    \label{fig:training_curves}
\end{figure}

\newpage
\subsection{Métricas de rendimiento}

Las métricas de rendimiento obtenidas son las siguientes:

\begin{itemize}
    \item \textbf{Precisión}: 84.3\% en el conjunto de validación, un resultado considerado satisfactorio para el objetivo del proyecto.
    
    \item \textbf{Matriz de confusión}: Los resultados muestran una mayor confusión entre las clases \texttt{red} y \texttt{trash} en comparación con la clase \texttt{green}.
    
    \item \textbf{Curvas ROC}: Se obtuvieron valores AUC superiores a 0.95 para todas las clases, lo que indica un excelente poder discriminativo del modelo.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/figures/confusion_matrix.png}
    \caption{Matriz de confusión del modelo en el conjunto de validación}
    \label{fig:confusion_matrix}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_RED.png}
        \caption{Curva ROC para la clase \texttt{RED}}
        \label{fig:roc_red}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_GREEN.png}
        \caption{Curva ROC para la clase \texttt{GREEN}}
        \label{fig:roc_green}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_TRASH.png}
        \caption{Curva ROC para la clase \texttt{TRASH}}
        \label{fig:roc_trash}
    \end{subfigure}
    \caption{Curvas ROC para cada una de las clases}
    \label{fig:roc_curves}
\end{figure}


\newpage
\subsection{Análisis de resultados}

El análisis de los resultados revela los siguientes hallazgos:

\begin{itemize}
    \item La arquitectura LSTM demuestra una capacidad efectiva para capturar patrones relevantes en las señales EEG.
    
    \item El refinamiento realizado en abril de 2025 produjo mejoras significativas, incrementando la precisión del 55\% inicial a más del 84\% mediante la ampliación del dataset.
    
    \item Las clases RED y GREEN presentan patrones más distinguibles, mientras que la clase TRASH muestra una mayor variabilidad inherente.
    
    \item La variabilidad en los procesos cognitivos de visualización de colores entre usuarios constituye un factor relevante que requiere protocolos estandarizados para la captura de datos.
\end{itemize}

\subsection{Exportación del modelo}

Completado el entrenamiento, se procedió a la exportación del modelo al formato ONNX para su integración en el proyecto desarrollado en Rust. El proceso implementado incluye:

\begin{itemize}
    \item Convertir de PyTorch a ONNX con \texttt{torch.onnx.export}.
    \item Especificar ejes dinámicos para lotes variables.
    \item Optimizar con plegado de constantes.
    \item Guardar en \texttt{build/neural\_analytics.onnx}.
\end{itemize}

Esta configuración permite la utilización del modelo mediante \texttt{tract-onnx} en el servicio de inferencia, manteniendo el rendimiento alcanzado durante el entrenamiento.

\chapter{Entrenamiento del modelo}\label{ch:model_training}

Después de todos los meses que me llevó trabajar en la arquitectura del sistema, finalmente llegué a la parte que más me emocionaba y a la vez me daba más miedo: entrenar el modelo que clasificaría las señales EEG. Honestamente, no tenía ni idea de si iba a funcionar o si me iba a quedar atascado en este paso para siempre.

Este capítulo documenta todo el proceso que seguí para entrenar el modelo, con todos sus altibajos, frustraciones y momentos de "¡por fin funciona!". Como en todo el proyecto, las cosas fueron bastante más complicadas de lo que esperaba al principio.

\section{Descripción de la arquitectura}

Elegir la arquitectura neuronal fue una de esas decisiones que me tuvo despierto varias noches. Al final me decidí por combinar redes LSTM (Long Short-Term Memory) con capas densas, principalmente porque había leído que las LSTM eran buenas para procesar secuencias temporales, y las señales EEG son exactamente eso. 

El objetivo era procesar y clasificar secuencias temporales de datos neurofisiológicos, aunque al principio no tenía muy claro si 62 puntos por ventana eran suficientes o demasiados.

\subsection{Estructura de la red neuronal}

Diseñar una arquitectura híbrida con redes LSTM y capas densas me llevó muchísimas pruebas y errores. La hice específicamente para procesar señales EEG de los cuatro canales que había elegido: T3, T4, O1 y O2. El sistema clasifica estas señales en RED, GREEN y TRASH, aunque inicialmente había pensado en más categorías hasta que me di cuenta de que era mejor empezar simple.

Probé varias configuraciones diferentes—algunas con más capas, otras con menos, unas con diferentes números de neuronas—y esta fue la que finalmente mejor funcionó después de semanas de experimentación.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.35\textwidth]{assets/figures/neural_analytics.onnx.png}
    \caption{Arquitectura del modelo de clasificación de señales EEG}
    \label{fig:model_architecture}
\end{figure}

Los componentes principales son:

\begin{itemize}
    \item \textbf{Capa LSTM}: Una capa LSTM con 64 unidades. Captura patrones temporales en las señales. Configuré \texttt{batch\_first=True} para que la entrada tenga la forma (batch\_size, seq\_length, features).
    
    \item \textbf{Capas densas}: Después de la LSTM, hay varias capas:
    \begin{itemize}
        \item Primera capa densa: Reduce de 64 a 32 unidades.
        \item Activación ReLU: Añade no-linealidad.
        \item Segunda capa densa: Proyecta a 3 neuronas de salida.
        \item Softmax: Normaliza las salidas como probabilidades.
    \end{itemize}
\end{itemize}

El flujo de datos es así:

\begin{enumerate}
    \item Entra una secuencia de 62 puntos, cada uno con 4 características.
    \item La LSTM procesa esto y saca 64 características por punto.
    \item Se toma el último estado de la secuencia.
    \item Este pasa por las capas densas con ReLU.
    \item La capa final con Softmax da la probabilidad para cada clase.
\end{enumerate}

\subsection{Parámetros del modelo}

Los principales parámetros son:

\begin{itemize}
    \item \texttt{INPUT\_SIZE = 4}: Los cuatro canales.
    \item \texttt{HIDDEN\_SIZE = 64}: Unidades en la capa LSTM.
    \item \texttt{NUM\_CLASSES = 3}: Las tres categorías.
    \item \texttt{WINDOW\_SIZE = 62}: Tamaño de ventana para secuencias.
    \item \texttt{BATCH\_SIZE = 64}: Muestras por lote en entrenamiento.
\end{itemize}

\section{Preprocesamiento de los datos}

El preprocesamiento es crucial para tener buenas entradas. Implementé varias fases desde la captura hasta generar ventanas deslizantes.

\subsection{Adquisición y estructuración del dataset}

El dataset tiene esta estructura:

\begin{itemize}
    \item \textbf{Organización por clases}: Archivos CSV en directorios según clase:
    \begin{itemize}
        \item \texttt{/red/}: Datos mientras el usuario piensa en rojo.
        \item \texttt{/green/}: Datos mientras piensa en verde.
        \item \texttt{/trash/}: Datos que no encajan en lo anterior.
    \end{itemize}
    
    \item \textbf{Formato}: Cada CSV tiene mediciones de T3, T4, O1 y O2 en columnas.
\end{itemize}

\subsection{Etapas de preprocesamiento}

El proceso está en la función \texttt{neural\_analytics\_preprocessor} y hace:

\begin{enumerate}
    \item \textbf{Normalización}: Escala los canales EEG al rango [0,1].
    
    \item \textbf{Extracción de etiquetas}: Saca la clase del nombre del directorio.
    
    \item \textbf{Codificación one-hot}: Convierte etiquetas a vectores:
    \begin{itemize}
        \item \texttt{red}: [1, 0, 0]
        \item \texttt{green}: [0, 1, 0]
        \item \texttt{trash}: [0, 0, 1]
    \end{itemize}
    
    \item \textbf{Ventanas deslizantes}: Para cada CSV, crea ventanas con solapamiento.
\end{enumerate}

\subsection{Implementación del dataset}

Hice una clase \texttt{NeuralAnalyticsDataset} que hereda de \texttt{Dataset} de PyTorch. Esta clase:

\begin{itemize}
    \item Recorre el directorio y procesa los CSV.
    \item Aplica el preprocesamiento.
    \item Guarda ventanas y etiquetas.
    \item Convierte a tensores de PyTorch.
    \item Implementa \texttt{\_\_len\_\_} y \texttt{\_\_getitem\_\_}.
\end{itemize}

En la inicialización, divido en entrenamiento (80\%) y validación (20\%) con \texttt{train\_test\_split}.

\section{Resultados del entrenamiento}

Usé PyTorch para entrenar. Me gustó por su flexibilidad y rendimiento. Estos son los resultados.

\subsection{Configuración del entrenamiento}

Configuré así el entrenamiento:

\begin{itemize}
    \item \textbf{Función de pérdida}: \texttt{CrossEntropyLoss}.
    
    \item \textbf{Optimizador}: Adam con tasa inicial 0.001.
    
    \item \textbf{Planificador}: \texttt{ReduceLROnPlateau} que reduce la tasa si la pérdida se estanca.
    
    \item \textbf{Épocas}: 1000, con evaluaciones periódicas.
    
    \item \textbf{Monitorización}: TensorBoard para ver métricas en tiempo real.
\end{itemize}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/loss_vs_epochs.png}
        \caption{Evolución de la pérdida durante el entrenamiento}
        \label{fig:loss_vs_epochs}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/accuracy_vs_epochs.png}
        \caption{Evolución de la precisión durante el entrenamiento}
        \label{fig:accuracy_vs_epochs}
    \end{subfigure}
    \caption{Curvas de entrenamiento del modelo Neural Analytics}
    \label{fig:training_curves}
\end{figure}

\newpage
\subsection{Métricas de rendimiento}

Estas son las métricas que obtuve:

\begin{itemize}
    \item \textbf{Precisión}: 84.3\% en validación. Bastante bien.
    
    \item \textbf{Matriz de confusión}: Muestra más confusión entre \texttt{red} y \texttt{trash} que con \texttt{green}.
    
    \item \textbf{Curvas ROC}: Valores AUC superiores a 0.95 para todas las clases. Muy buen poder discriminativo.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/figures/confusion_matrix.png}
    \caption{Matriz de confusión del modelo en el conjunto de validación}
    \label{fig:confusion_matrix}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_RED.png}
        \caption{Curva ROC para la clase \texttt{RED}}
        \label{fig:roc_red}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_GREEN.png}
        \caption{Curva ROC para la clase \texttt{GREEN}}
        \label{fig:roc_green}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{assets/figures/roc_curve_TRASH.png}
        \caption{Curva ROC para la clase \texttt{TRASH}}
        \label{fig:roc_trash}
    \end{subfigure}
    \caption{Curvas ROC para cada una de las clases}
    \label{fig:roc_curves}
\end{figure}


\newpage
\subsection{Análisis de resultados}

Al analizar todo esto, veo que:

\begin{itemize}
    \item La LSTM capta bien los patrones de las señales EEG.
    
    \item El refinamiento de abril 2025 mejoró mucho. Pasamos de 55\% a más de 84\% de precisión al ampliar el dataset.
    
    \item RED y GREEN tienen patrones claros. TRASH varía más.
    
    \item La forma en que los usuarios piensan en colores afecta mucho. Necesitamos un protocolo estándar para capturar datos.
\end{itemize}

\subsection{Exportación del modelo}

Tras entrenar, exporté el modelo a ONNX para integrarlo en el proyecto en Rust. El proceso fue:

\begin{itemize}
    \item Convertir de PyTorch a ONNX con \texttt{torch.onnx.export}.
    \item Especificar ejes dinámicos para lotes variables.
    \item Optimizar con plegado de constantes.
    \item Guardar en \texttt{build/neural\_analytics.onnx}.
\end{itemize}

Con esto, el modelo puede usarse con \texttt{tract-onnx} en el servicio de inferencia, manteniendo el rendimiento que conseguí durante el entrenamiento.
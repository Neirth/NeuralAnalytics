\chapter{Modelos de Deep Learning}\label{ch:deep_learning_models}

A través de este capítulo, se describen los modelos de Deep Learning \cite{raschka2022machine} implementados en el proyecto, así como los conceptos fundamentales y la arquitectura de cada uno. También se detallan las métricas de evaluación y el proceso de validación cruzada utilizado para evaluar su rendimiento.

La selección de estos modelos constituyó un proceso de análisis técnico detallado. Tras la evaluación de múltiples arquitecturas, se optó por aquellas que demostraron una capacidad superior para detectar patrones temporales en señales EEG, especialmente en ventanas cortas —un requisito fundamental para la clasificación en tiempo real demandada por el sistema—.

Aunque seguramente ya existen trabajos previos que abordan la clasificación de señales EEG mediante Deep Learning, en este proyecto se buscó una implementación desde cero, con el objetivo de comprender, y aprender, a fondo como se puede llegar a construir un modelo de clasificación adaptado a este contexto. Por tanto, se ha evitado el uso de modelos preentrenados o bibliotecas de alto nivel que abstraigan demasiado los detalles del proceso de entrenamiento y ajuste.

\newpage
\section{Conceptos Fundamentales}

\subsection{Ventanas Temporales}
Las ventanas temporales en el procesamiento de señales EEG representan segmentos discretos de tiempo durante los cuales se recopilan datos. En este proyecto, estas ventanas capturan patrones de actividad cerebral asociados al pensamiento de diferentes colores. La longitud de la ventana se reveló como un parámetro de alta sensibilidad: si era demasiado corta, no capturaba suficiente información para la clasificación; si era excesivamente larga, introducía latencias consideradas inaceptables para una aplicación en tiempo real.

Tras pruebas exhaustivas con diferentes configuraciones, se determinó que ventanas de 62 muestras ofrecían el equilibrio más adecuado para el sistema. Esta longitud precisamente fue la que permitió capturar la dinámica de la actividad cerebral sin comprometer la inmediatez de la respuesta del sistema.

\subsection{One-Hot Encoding}
El One-Hot Encoding \cite{raschka2022machine} es una técnica de preprocesamiento que transforma etiquetas categóricas (en este caso, colores) en vectores binarios. Por ejemplo, para tres colores:

\begin{figure}[h!]
    \centering
    \begin{tabular}{c|c}
        Color & Vector One-Hot \\
        \hline
        Rojo & [1, 0, 0] \\
        Verde & [0, 1, 0] \\
        Azul & [0, 0, 1]
    \end{tabular}
    \caption{Ejemplo de One-Hot Encoding para tres colores.}
    \label{fig:one_hot_encoding}
\end{figure}

Esta técnica es de gran utilidad cuando se trabaja con datos categóricos sin relación ordinal entre sí. A diferencia de la codificación de etiquetas ordinales, donde se asigna un valor numérico a cada categoría según un orden predefinido, One-Hot Encoding crea una nueva columna para cada categoría posible.

Por ejemplo, si existe una columna \textquotedblleft color\textquotedblright{} con las opciones \textquotedblleft rojo\textquotedblright{}, \textquotedblleft verde\textquotedblright{} y \textquotedblleft azul\textquotedblright{}, esta técnica la transforma en tres columnas nuevas. Cada fila tendrá un 1 en la columna de su color correspondiente y 0 en las demás.

Inicialmente, existió una indecisión entre utilizar esta técnica o una codificación ordinal más simple, pues en ciertos experimentos preliminares se habían observado comportamientos similares con ambas. Sin embargo, conceptualmente el One-Hot Encoding representa de manera más fidedigna la naturaleza de los datos —no existe una relación ordinal inherente entre los colores— por lo que se optó por implementar este enfoque, considerado más robusto.

\section{Arquitectura del Modelo}

\subsection{Función de Activación ReLU}
La función ReLU (Rectified Linear Unit) se consolidó como un componente esencial del modelo implementado, debido a características que la hacen especialmente adecuada:

\begin{figure}[h!]
    \centering
    \begin{equation}
        f(x) = max(0, x)
    \end{equation}
    \caption{Ecuación de la función ReLU.}
    \label{fig:relu_equation}
\end{figure}

ReLU es una función de activación no lineal que aborda el problema del desvanecimiento del gradiente, presente en funciones como tanh o sigmoide. Este problema ocurre cuando, por ejemplo, para valores de entrada grandes ($z_1 = 20$ y $z_2 = 25$), las funciones tanh y sigmoide producen salidas prácticamente idénticas ($\sigma(z_1) \approx \sigma(z_2) \approx 1.0$) debido a su comportamiento asintótico.

Las principales ventajas que condujeron a la selección de ReLU son:

\begin{itemize}
    \item \textbf{Gradiente Constante}: Para valores positivos de entrada, la derivada es siempre 1, lo que evita el desvanecimiento del gradiente.
    \item \textbf{Eficiencia Computacional}: Su implementación es simple y rápida, requiriendo solo una comparación con cero.
    \item \textbf{No Linealidad}: A pesar de su simplicidad, mantiene la capacidad para aprender funciones complejas.
    \item \textbf{Activación Dispersa}: Produce activaciones dispersas, ya que cualquier entrada negativa se convierte en cero.
\end{itemize}

La implementación de ReLU estándar resultó ser la opción más práctica y eficiente para el caso de uso específico de este proyecto.

\subsection{LSTM (Long Short-Term Memory)}

Las LSTM fueron diseñadas para superar el problema del desvanecimiento del gradiente, frecuente en redes neuronales recurrentes (RNN) estándar. Este problema tiene lugar por la multiplicación repetida de gradientes durante la retropropagación a través del tiempo (BPTT), lo que provoca que los gradientes se vuelvan extremadamente pequeños (desvanecimiento) o grandes (explosión).

La prima aproximación al proyecto utilizaba RNNs convencionales, pero pronto se encontraron limitaciones al procesar secuencias temporales largas. Las LSTM ofrecían una solución efectiva a este problema, aunque con una mayor complejidad computacional —un factor que inicialmente generó cierta preocupación, dado el requisito de ejecución en tiempo real—.

Para una mejor comprensión de este problema, considérese una RNN con una sola unidad oculta. La derivada de la función de pérdida respecto a la entrada neta posee un factor multiplicativo que puede volverse muy pequeño o muy grande según el peso recurrente. Si este peso es menor que 1, el gradiente se desvanece; si es mayor que 1, explota.

Las LSTM abordan esta cuestión mediante celdas de memoria que mantienen información durante períodos prolongados. Cada celda incluye tres tipos de puertas: olvido, entrada y salida.

\begin{itemize}
    \item \textbf{Puerta de Olvido (Forget Gate)}: Decide qué información descartar de la memoria. Se calcula mediante:
    \begin{equation}
        f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)
    \end{equation}
    \item \textbf{Puerta de Entrada (Input Gate)}: Decide qué nueva información almacenar. Se calcula como:
    \begin{equation}
        i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
    \end{equation}
    \item \textbf{Valor Candidato (Candidate Value)}: Representa la nueva información potencial. Se calcula con:
    \begin{equation}
        \tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)
    \end{equation}
    \item \textbf{Puerta de Salida (Output Gate)}: Decide qué parte de la memoria se usará para la salida. Se calcula así:
    \begin{equation}
        o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)
    \end{equation}
\end{itemize}

La celda de memoria se actualiza de la siguiente forma:
\begin{equation}
    C_t = f_t \cdot C_{t-1} + i_t \cdot \tilde{C}_t
\end{equation}

Y la salida se calcula como:
\begin{equation}
    h_t = o_t \cdot \tanh(C_t)
\end{equation}

Estas ecuaciones pueden parecer complejas en una primera instancia, pero la intuición subyacente es relativamente clara: las LSTM aprenden a controlar qué información recordar, actualizar u olvidar en cada paso temporal. Al implementar esta arquitectura, fue posible capturar dependencias temporales en las señales EEG que resultaron fundamentales para distinguir patrones asociados a diferentes colores.

\subsection{Función Softmax}
La función Softmax es una versión suavizada de argmax; en lugar de proporcionar un único índice de clase, ofrece la probabilidad de cada una. Esto permite calcular probabilidades significativas en configuraciones multiclase.

En Softmax, la probabilidad de que una muestra con entrada neta $z$ pertenezca a la clase $i$ se calcula con un término de normalización en el denominador, que suma las funciones lineales ponderadas exponencialmente:

\begin{figure}[h!]
    \centering
    \begin{equation}
        p(z) = \sigma(z) = \frac{e^{z_i}}{\sum_{j=1}^M e^{z_j}}
    \end{equation}
    \caption{Ecuación de la función Softmax.}
    \label{fig:softmax_equation}
\end{figure}

Las probabilidades resultantes suman 1, como es de esperar. También es destacable que la etiqueta predicha es la misma que al aplicar argmax a la salida logística.

Durante el desarrollo del modelo, se consideró brevemente la utilización de una capa sigmoide final con entrenamiento independiente para cada clase (enfoque one-vs-all), pero la implementación con Softmax resultó más conveniente y directa, además de proporcionar interpretaciones probabilísticas más intuitivas de las predicciones.

\section{Evaluación del Modelo}

\subsection{Métricas de Evaluación}
Para evaluar el rendimiento del modelo, se utilizó un conjunto de métricas complementarias:
\begin{itemize}
    \item \textbf{Accuracy}: Proporción de predicciones correctas sobre el total. Aunque es una métrica intuitiva, no siempre refleja el rendimiento real cuando las clases están desbalanceadas.
    
    \item \textbf{Matriz de Confusión}: Visualización detallada de aciertos y errores por clase. Esta herramienta resultó de particular utilidad para identificar patrones específicos de confusión entre colores, lo que permitió ajustar el preprocesamiento de señales para mejorar la discriminación en casos problemáticos.
    
    \item \textbf{ROC-AUC}: Área bajo la curva ROC para evaluación multiclase. Esta métrica se consideró especialmente valiosa por su robustez ante el desbalanceo de clases, un problema que se manifestó en algunas sesiones de recopilación de datos donde ciertos colores mostraban frecuencias de aparición variables.
\end{itemize}

La combinación de estas métricas proporcionó una visión integral del rendimiento del modelo en diferentes escenarios y condiciones, guiando el proceso iterativo de mejora hasta alcanzar resultados considerados satisfactorIOS para la aplicación en tiempo real.

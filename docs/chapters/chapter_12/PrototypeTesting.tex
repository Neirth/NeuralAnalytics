\chapter{Validación del Prototipo}\label{ch:prototype_testing}

Este capítulo documenta exhaustivamente el proceso de validación implementado, abarcando desde verificaciones elementales hasta evaluaciones de complejidad considerable, todo ello en conformidad con la normativa vigente para software de dispositivos médicos. 

\section{Marco Normativo de Validación}

\subsection{Normativa Aplicable}

Para la validación de Neural Analytics, se siguieron las directrices de la norma UNE-EN 62304 \cite{UNE-EN-62304}, "Software de dispositivos médicos - Procesos del ciclo de vida del software". Esta norma establece requisitos específicos para todo el proceso de desarrollo y mantenimiento del software en dispositivos médicos, caracterizándose por su rigor metodológico.

\subsection{Clasificación del Software}

Según la sección 4.3 de la norma UNE-EN 62304, el software Neural Analytics se clasifica como dispositivo de \textbf{Clase A}, debido a que:

\begin{itemize}
    \item No puede contribuir directamente a situaciones peligrosas, ya que funciona únicamente como herramienta de monitorización sin capacidad de realizar acciones directas sobre el paciente.
    \item Su uso está destinado a aplicaciones no críticas de interfaz cerebro-computadora.
    \item El sistema incluye restricciones de uso explícitas que previenen su aplicación en escenarios clínicos críticos.
\end{itemize}

Esta clasificación determina el nivel de rigor aplicable a las pruebas y documentación del software. Los procesos de Clase A son menos exigentes que los correspondientes a las Clases B o C.

\section{Estrategia de Pruebas}

Siguiendo los requisitos de la norma UNE-EN 62304 para software de Clase A, se implementó una estrategia de pruebas estructurada en tres niveles:

\begin{itemize}
    \item \textbf{Pruebas unitarias}: Verificar que cada componente individual del software funcione correctamente.
    \item \textbf{Pruebas de integración}: Verificar que los componentes trabajen conjuntamente.
    \item \textbf{Pruebas del sistema}: Verificar que todo el sistema funcione correctamente en conjunto.
\end{itemize}

Como parte del alcance definido, la estrategia de pruebas se focalizó en los dos componentes principales: \texttt{neural\_analytics\_core} y \texttt{neural\_analytics\_gui}, módulos que constituyen el producto final utilizado por el usuario. Esta focalización permite concentrar los esfuerzos de validación en los componentes que capturan la mayor parte de la funcionalidad crítica del sistema.

\subsection{Herramientas y Entorno de Pruebas}

Para ejecutar las pruebas se utilizó el siguiente entorno:

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{|p{4cm}|p{8cm}|}
        \hline
        \textbf{Elemento} & \textbf{Descripción} \\
        \hline
        Hardware principal & Raspberry Pi 4 Model B (8GB RAM) \\
        \hline
        Sistema operativo & Poky Linux 64-bit \\
        \hline
        Dispositivo EEG & BrainBit (4 canales) \\
        \hline
        Dispositivos actuadores & Bombillas inteligentes Tapo L530E \\
        \hline
        Framework de pruebas unitarias & Rust Test Framework \\
        \hline
        Herramientas de cobertura & cargo-llvm-cov \\
        \hline
        Herramientas de monitorización & htop \\
        \hline
    \end{tabular}
    \caption{Entorno de pruebas para Neural Analytics}
    \label{tab:test_environment}
\end{table}

\newpage
\section{Pruebas Unitarias}

\subsection{Estrategia de Pruebas Unitarias}

Las pruebas unitarias se diseñaron para verificar el correcto funcionamiento de los componentes individuales del software, con especial énfasis en:

\begin{itemize}
    \item Funcionamiento correcto de módulos aislados.
    \item Manejo adecuado de casos límite.
    \item Gestión de errores.
    \item Consistencia en la interfaz de los componentes.
\end{itemize}

De acuerdo con la sección 5.5.3 de la norma UNE-EN 62304, para cada prueba unitaria se definieron criterios de aceptación explícitos antes de su ejecución. Esta práctica permite optimizar el tiempo de depuración cuando las pruebas fallan.

\subsubsection{Enfoque para Arquitectura Hexagonal}

La arquitectura hexagonal adoptada en el sistema Neural Analytics requiere un enfoque específico para las pruebas unitarias. Se implementaron las siguientes estrategias:

\begin{itemize}
    \item \textbf{Aislamiento de componentes}: Los tests se ejecutan sobre componentes aislados mediante la inyección de dependencias simuladas (mocks) para puertos y adaptadores.
    
    \item \textbf{Doble Testing}: Para cada puerto se desarrollaron tests tanto para la interfaz como para sus implementaciones concretas (adaptadores).
    
    \item \textbf{Pruebas de casos de uso puros}: Los casos de uso se probaron independientemente de sus adaptadores de entrada/salida, verificando únicamente el comportamiento esperado según la lógica de negocio.
\end{itemize}

\newpage
\subsection{Pruebas Unitarias del Core (\texttt{neural\_analytics\_core})}

El módulo core del sistema, responsable de la lógica central de procesamiento y gestión de eventos, fue sometido a pruebas unitarias exhaustivas:

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|p{3cm}|p{6cm}|p{4cm}|p{2cm}|}
        \hline
        \textbf{Módulo} & \textbf{Aspectos probados} & \textbf{Criterio de aceptación} & \textbf{Resultado} \\
        \hline
        Adaptadores EEG & Conexión, lectura de datos, gestión de desconexiones & Lectura consistente de datos sin pérdida de muestras & PASA \\
        \hline
        Servicio de inferencia & Carga del modelo ONNX, preprocesamiento, inferencia & Predicciones coherentes con valores esperados & PASA \\
        \hline
        Controlador de dispositivos & Conexión con bombillas inteligentes, cambio de estados & Respuesta en < 300ms a cambios de estado & PASA \\
        \hline
        Máquina de estados & Transiciones correctas entre estados del sistema & Comportamiento consistente ante eventos & PASA \\
        \hline
        Comunicación entre componentes & Bus de eventos, suscripciones, publicaciones & Entrega confiable de eventos & PASA \\
        \hline
    \end{tabular}
    }
    \caption{Resultados de pruebas unitarias del módulo Core}
    \label{tab:unit_tests_core}
\end{table}

\subsubsection{Tests para Adaptadores de Hardware Simulado}

Un componente crítico del sistema son los adaptadores para hardware, como el dispositivo EEG BrainBit y las bombillas inteligentes. Para facilitar las pruebas sin dependencia de hardware físico, se implementaron adaptadores mock que simulan el comportamiento del hardware real:

\begin{itemize}
    \item \textbf{MockHeadsetAdapter}: Simula el comportamiento del dispositivo BrainBit, generando datos EEG sintéticos y simulando operaciones como conexión/desconexión y cambios de modo.
    
    \item \textbf{MockSmartBulbAdapter}: Simula el comportamiento de las bombillas inteligentes, permitiendo probar los casos de uso de control domótico sin necesidad de dispositivos físicos.
\end{itemize}

La implementación de estos adaptadores mock permitió realizar pruebas unitarias exhaustivas sin depender de hardware real, lo que aceleró significativamente el proceso de desarrollo y validación.

\newpage
\subsubsection{Pruebas Unitarias de Casos de Uso}

Siguiendo el principio de que cada componente debe ser verificable de forma independiente, se aplicó un enfoque estricto donde cada caso de uso en el sistema tiene su correspondiente test unitario implementado dentro del propio archivo del caso de uso mediante el atributo \texttt{\#[cfg(test)]}. Esta práctica de coubicación de pruebas con código facilita el mantenimiento y asegura que las pruebas evolucionan junto con la implementación —un aspecto cuya fundamental importancia se hizo evidente tras varias experiencias con tests desactualizados—. Esta organización garantiza la verificabilidad directa de cada componente funcional, cumpliendo con la sección 5.1.2 de la norma UNE-EN 62304 que establece que el software debe ser verificable:

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|p{7cm}|p{7cm}|}
        \hline
        \textbf{Caso de Uso} & \textbf{Aspectos verificados} \\
        \hline
        \texttt{predict\_color\_thinking\_use\_case.rs} & Procesamiento de señales EEG, generación de predicciones precisas con datos sintéticos \\
        \hline
        \texttt{search\_headband\_use\_case.rs} & Secuencia de búsqueda, protocolo de conexión, manejo de errores de detección \\
        \hline
        \texttt{update\_status\_use\_case.rs} & Transiciones de estado basadas en eventos, validación de precondiciones \\
        \hline
        \texttt{disconnect\_headband\_use\_case.rs} & Secuencia de desconexión, liberación correcta de recursos \\
        \hline
        \texttt{extract\_calibration\_use\_case.rs} & Verificación de impedancia, validación de señales, cambio de modo de trabajo \\
        \hline
        \texttt{extract\_extraction\_use\_case.rs} & Adquisición de datos EEG, validación de formato y estructura, detección de dispositivo no conectado \\
        \hline
    \end{tabular}
    }
    \caption{Correspondencia entre casos de uso y tests unitarios}
    \label{tab:use_case_tests}
\end{table}

Con esta metodología, se aseguró que cualquier cambio en un caso de uso tuviera que pasar primero por su test correspondiente, lo que proporcionaba una considerable tranquilidad sobre la estabilidad del sistema. Para cada test se utilizaron adaptadores simulados (mocks) que permitían centrarse únicamente en la lógica de negocio sin depender de componentes externos que pudieran complicar las pruebas.

\newpage
\subsection{Cobertura de Código}

Un aspecto de gran interés durante el desarrollo fue determinar si realmente se estaba probando todo el código escrito. Para ello, se implementó un análisis de cobertura usando cargo-llvm-cov, que proporcionaba métricas bastante detalladas sobre qué partes del código se ejecutaban durante las pruebas y cuáles no.

Los resultados fueron reveladores: aunque algunos componentes tenían una cobertura excelente, otros claramente necesitaban más atención. Se constató que era más difícil de lo previsto conseguir una cobertura alta y consistente en todos los módulos.

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|l|c|c|c|c|c|}
        \hline
        \textbf{Componente} & \textbf{Líneas Total} & \textbf{Líneas Cubiertas} & \textbf{\% Líneas} & \textbf{\% Funciones} & \textbf{\% Regiones} \\
        \hline
        model\_inference\_service.rs & 411 & 298 & 72.51\% & 75.00\% & 54.86\% \\
        \hline
        disconnect\_headband\_use\_case.rs & 212 & 211 & 99.53\% & 95.00\% & 97.50\% \\
        \hline
        extract\_extraction\_use\_case.rs & 252 & 248 & 98.41\% & 94.44\% & 88.89\% \\
        \hline
        extract\_calibration\_use\_case.rs & 252 & 250 & 99.21\% & 94.44\% & 91.67\% \\
        \hline
        predict\_color\_thinking\_use\_case.rs & 160 & 159 & 99.38\% & 93.75\% & 92.00\% \\
        \hline
        search\_headband\_use\_case.rs & 198 & 197 & 99.49\% & 95.00\% & 97.50\% \\
        \hline
        update\_light\_status\_use\_case.rs & 209 & 208 & 99.52\% & 95.00\% & 97.37\% \\
        \hline
        state\_machine/state\_machine.rs & 780 & 715 & 91.67\% & 90.91\% & 75.81\% \\
        \hline
        \textbf{TOTAL} & \textbf{2970} & \textbf{2417} & \textbf{81.38\%} & \textbf{78.88\%} & \textbf{57.00\%} \\
        \hline
    \end{tabular}
    }
    \caption{Métricas de cobertura de código por componente}
    \label{tab:code_coverage_metrics}
\end{table}

Los resultados mostraron aspectos muy interesantes. Los casos de uso principales, que son realmente el corazón del sistema, tenían una cobertura excelente (98-99\% de líneas), lo que tranquilizó mucho porque significaba que se estaba probando tanto el flujo normal como todos los casos de error que se habían podido identificar. La máquina de estados, que es bastante crítica porque coordina todo el flujo de trabajo, tuvo una cobertura bastante satisfactoria (91.67\%), lo que era un buen indicativo de que las transiciones y estados estaban bien cubiertos.

El servicio de inferencia fue donde se hizo evidente la complejidad: solo se consiguió un 72.51\% de cobertura porque es increíblemente difícil simular todas las posibles situaciones que pueden ocurrir al procesar señales EEG reales y trabajar con modelos de machine learning. Ahí se constató que no todo se puede probar de manera automatizada.

La cobertura total del 81.38\% se consideró bastante aceptable, y además se alineaba bien con los principios de la norma UNE-EN 62304 para software médico de Clase A, que básicamente establece que el nivel de pruebas tiene que ser proporcional al riesgo del software.

\subsubsection{Justificación de la elección de un 80\% de cobertura}

La decisión sobre el objetivo de cobertura requirió una reflexión considerable, pero finalmente se optó por un 80\% basándose en varios criterios que tenían sentido tanto desde el punto de vista técnico como normativo:

\begin{enumerate}
    \item \textbf{Enfoque basado en riesgos}: Siguiendo la sección 4.3 de la norma UNE-EN 62304, el foco se centró en conseguir una cobertura casi perfecta (cercana al 100\%) para los componentes del dominio que implementan la lógica crítica, mientras que se adoptó una postura más flexible con los componentes de infraestructura que no afectan directamente al funcionamiento principal.
    
    \item \textbf{Limitaciones reales del testing automatizado}: Se reconoció que hay aspectos que simplemente no se pueden probar de manera automática —especialmente todo lo relacionado con hardware real (el dispositivo EEG y las bombillas inteligentes) o el rendimiento de los modelos de machine learning—. Intentarlo habría supuesto una inversión de tiempo desproporcionada.
    
    \item \textbf{Las pruebas manuales también son relevantes}: La cobertura automatizada se complementó con un conjunto exhaustivo de pruebas manuales que cubrían específicamente esos aspectos no automatizables.
\end{enumerate}

\subsubsection{La relevancia de las pruebas manuales}

Para compensar las limitaciones de las pruebas automatizadas, se implementó un proceso bastante riguroso de pruebas manuales con hardware real. Estas pruebas fueron fundamentales porque permitieron verificar aspectos que ningún test automatizado podría cubrir:

\begin{itemize}
    \item \textbf{Validación con señales EEG reales}: Probar el sistema con señales cerebrales reales en diferentes condiciones —cansancio, concentración, distracción, etc.—. Esto era imposible de simular completamente en tests automatizados.
    
    \item \textbf{Medición de latencia end-to-end}: Cronometrar exactamente cuánto tardaba desde que se pensaba en un color hasta que se encendía la bombilla correspondiente. Estas mediciones solo tenían sentido con hardware real.
    
    \item \textbf{Pruebas de robustez a largo plazo}: Usar el sistema durante sesiones de más de 30 minutos para observar cómo se comportaba con la fatiga del usuario, la deriva de la señal y otros efectos que solo aparecen con el tiempo.
    
    \item \textbf{Evaluación de usabilidad}: Probar si la interfaz realmente era intuitiva y fácil de usar —algo que las cifras de cobertura jamás podrían indicar—.
\end{itemize}

Estas pruebas manuales confirmaron que el sistema funcionaba correctamente en condiciones reales, especialmente en todos esos aspectos que las métricas de cobertura no podían reflejar. Al combinar los resultados satisfactorios de estas pruebas con la cobertura automatizada del 81.38\%, se consiguió un nivel de confianza bastante alto en la calidad del sistema, cumpliendo con los requisitos de la norma UNE-EN 62304.

La distribución de cobertura varió considerablemente según el tipo de componente, lo cual, en última instancia, resultó coherente: se mantuvieron niveles altos (98\%) en la capa de dominio donde reside toda la lógica crítica, mientras que los servicios alcanzaron aproximadamente un 59\%, los puertos un 54\%, los adaptadores un 47\% y otros componentes auxiliares un 29\%. Esta distribución se consideró consistente con la estrategia de gestión de riesgos adoptada, que priorizaba la verificación exhaustiva de los componentes más críticos.

Al final, esta distribución confirmaba que se tenía mayor cobertura en los componentes realmente críticos del sistema (dominio y puertos), mientras que era relativamente menor en componentes de infraestructura y utilidades, lo que era exactamente el objetivo buscado.

\newpage
\subsection{Validación Manual de la Interfaz (\texttt{neural\_analytics\_gui})}

Para la interfaz gráfica se decidió no desarrollar pruebas unitarias automatizadas, principalmente porque sus componentes son presentacionales y no contienen lógica de negocio crítica que necesite verificación programática. Además, se constató que probar interfaces gráficas automáticamente puede ser más complicado que beneficioso; después de algunos intentos, se abandonó la idea por su fragilidad inherente. En su lugar, se optó por un enfoque de validación manual que permitía verificar el correcto funcionamiento de manera más natural:

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|p{3cm}|p{6cm}|p{4cm}|p{2cm}|}
        \hline
        \textbf{Componente} & \textbf{Aspectos validados} & \textbf{Criterio de aceptación} & \textbf{Resultado} \\
        \hline
        Vista principal & Renderizado de elementos, navegación entre secciones & Visualización correcta y respuesta a interacciones & PASA \\
        \hline
        Visualización de señales & Representación gráfica de señales EEG en tiempo real & Actualización fluida (>25 FPS) & PASA \\
        \hline
        Módulo de calibración & Detección de impedancias, guía de usuario & Feedback preciso sobre calidad de contacto & PASA \\
        \hline
        Panel de configuración & Gestión de preferencias, validación de entradas & Persistencia de configuraciones & PASA \\
        \hline
        Indicadores de estado & Visualización del estado del sistema y predicciones & Correspondencia con estados internos & PASA \\
        \hline
    \end{tabular}
    }
    \caption{Resultados de la validación manual del módulo GUI}
    \label{tab:manual_tests_gui}
\end{table}

\newpage

\section{Pruebas de Integración}

\subsection{Enfoque para las pruebas de integración}

Una vez que todas las pruebas unitarias estuvieron funcionando, el siguiente paso, que generaba mayor expectación, era verificar que todos los componentes trabajaran bien juntos. Para las pruebas de integración, se siguieron las recomendaciones de la sección 5.6 de la norma UNE-EN 62304, aunque adaptándolas al entorno de desarrollo particular.

El enfoque se centró principalmente en dos niveles de integración:

\begin{enumerate}
    \item \textbf{Integración intra-módulo}: Verificar que los componentes dentro del mismo módulo se comunicaran correctamente.
    \item \textbf{Integración inter-módulo}: Probar que el módulo core y la interfaz gráfica funcionaran bien juntos.
\end{enumerate}

Inicialmente, se pensó que sería más sencillo que las pruebas unitarias, pero pronto se hizo evidente que encontrar problemas de integración puede ser mucho más difícil porque los errores aparecen en las fronteras entre componentes.

\subsection{Descubrimientos con las pruebas de integración}

Los resultados fueron bastante satisfactorios, aunque fue necesario resolver algunos problemas interesantes durante el proceso:

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|p{4cm}|p{7cm}|p{2cm}|}
        \hline
        \textbf{Escenario de integración} & \textbf{Descripción} & \textbf{Resultado} \\
        \hline
        Core $\leftrightarrow$ Adaptador EEG & Flujo de datos desde el dispositivo EEG al procesador del Core & PASA \\
        \hline
        Core $\leftrightarrow$ Interfaz & Visualización de estados del sistema y datos en tiempo real & PASA \\
        \hline
        Servicio de inferencia $\leftrightarrow$ Máquina de estados & Transición correcta de estados basada en resultados de inferencia & PASA \\
        \hline
        Módulo de configuración $\leftrightarrow$ Componentes del sistema & Aplicación efectiva de configuraciones de usuario & PASA \\
        \hline
    \end{tabular}
    }
    \caption{Resultados de pruebas de integración}
    \label{tab:integration_tests}
\end{table}

\subsubsection{La prueba de mayor relevancia: Flujo completo de procesamiento EEG}

Una de las pruebas de integración cuyo diseño requirió más trabajo, pero que finalmente proporcionó mayor satisfacción, fue la verificación de todo el flujo de procesamiento de datos EEG de principio a fin. Esta prueba permitía evaluar toda la cadena de procesamiento desde que llegan los datos hasta que se genera una predicción.

El procedimiento fue el siguiente:
\begin{enumerate}
    \item Configurar el sistema con adaptadores simulados para el dispositivo EEG (para no depender del hardware físico).
    \item Inyectar datos EEG que representaban patrones cerebrales específicos conocidos.
    \item Ejecutar todo el ciclo de procesamiento de principio a fin.
    \item Verificar que el modelo de inferencia generaba predicciones coherentes con los datos de entrada.
    \item Comprobar que la interfaz se actualizaba mostrando la predicción correcta.
    \item Confirmar que el nivel de confianza superaba el umbral mínimo establecido (75\%).
\end{enumerate}

Esta prueba proporcionaba una gran confianza porque verificaba la integración de todo el sistema —desde la llegada de los datos EEG hasta su procesamiento y visualización—. Era como una prueba de que todos los componentes principales trabajaban en armonía, que era exactamente lo que se necesitaba confirmar.

\newpage
\section{Pruebas del Sistema}

Se llegó a las pruebas del sistema con una mezcla de expectación y nerviosismo: finalmente se iba a probar todo el sistema completo en condiciones que se asemejaran lo más posible al uso real. Estas pruebas se diseñaron siguiendo la sección 5.7 de la norma UNE-EN 62304, pero adaptándolas a las capacidades reales del prototipo.

\subsection{Los casos de prueba diseñados}

Se desarrollaron varios casos de prueba del sistema que cubrían desde los escenarios más básicos hasta situaciones más complejas que podrían ocurrir en el mundo real:


\begin{center}
\small
\begin{longtable}{|p{1cm}|p{3.5cm}|p{3.5cm}|p{3.5cm}|p{1.5cm}|}
    \hline
    \textbf{ID} & \textbf{Descripción} & \textbf{Procedimiento} & \textbf{Criterio de aceptación} & \textbf{Resultado} \\
    \hline
    \endfirsthead
    \hline
    \textbf{ID} & \textbf{Descripción} & \textbf{Procedimiento} & \textbf{Criterio de aceptación} & \textbf{Resultado} \\
    \hline
    \endhead
    SYS-01 & Inicialización del sistema & Iniciar la aplicación y verificar la carga de todos los módulos & Sistema operativo en <10s sin errores & PASA \\
    \hline
    SYS-02 & Conexión con dispositivo EEG & Encender el dispositivo BrainBit y conectarlo con la aplicación & Conexión establecida y datos fluyendo & PASA \\
    \hline
    SYS-03 & Calibración del dispositivo & Seguir el procedimiento de calibración & Impedancias aceptables en todos los canales & PASA \\
    \hline
    SYS-04 & Detección de pensamiento "rojo" & Usuario piensa en color rojo durante 10 segundos & Sistema identifica correctamente la intención & PASA \\
    \hline
    SYS-05 & Detección de pensamiento "verde" & Usuario piensa en color verde durante 10 segundos & Sistema identifica correctamente la intención & PASA \\
    \hline
    SYS-06 & Activación de dispositivo por pensamiento & Usuario piensa en color específico y se verifica actuación & Bombilla cambia al color detectado en <1s & PASA \\
    \hline
    SYS-07 & Operación continua & Sistema funciona por >30 minutos continuos & Sin degradación de rendimiento ni fugas de memoria & PASA \\
    \hline
    SYS-08 & Recuperación ante errores & Simular desconexión del dispositivo EEG durante operación & Sistema detecta error y permite reconexión & PASA \\
    \hline
    \caption{Casos de prueba del sistema}\label{fig:system_tests}
\end{longtable}
\end{center}


\newpage
\section{Pruebas de Seguridad}

Aunque para software de Clase A la norma no exige pruebas de seguridad súper exhaustivas, se decidió realizar algunas verificaciones básicas porque se quería asegurar que el sistema no comprometiera la seguridad del usuario ni generara riesgos innecesarios. Al fin y al cabo, se trata de un dispositivo que lee señales cerebrales, y eso siempre requiere un cuidado adicional.

\subsection{Gestión de los datos del usuario}

Uno de los aspectos que normalmente genera mayor preocupación en esta clase de proyecto es el tema de la privacidad de los datos. Se aseguró que:

\begin{itemize}
    \item Todos los datos EEG que captura el sistema se procesan localmente, sin enviar nada a servidores externos —esto proporcionaba una gran tranquilidad porque evitaba toda la complejidad legal y ética del manejo de datos médicos en la nube—.
    \item Los archivos de entrenamiento que se guardan están en formato anonimizado, sin posibilidad de identificar a la persona.
    \item El sistema no recopila ningún tipo de información personal identificable más allá de las señales EEG.
\end{itemize}

\subsection{Seguridad eléctrica}

Para la seguridad eléctrica, se tuvo la ventaja de usar el dispositivo BrainBit EEG, que ya cumple con los estándares FC y CE, por lo que su seguridad eléctrica y compatibilidad electromagnética estaban garantizadas. Como no se implementó hardware personalizado, no fue necesario realizar pruebas adicionales, pero sí se verificaron algunos aspectos básicos considerados importantes:

\begin{itemize}
    \item Que no hubiera interacciones eléctricas anómalas entre el dispositivo EEG y el sistema.
    \item Que el comportamiento fuera seguro mientras se carga el dispositivo.
    \item Que no se sobrecalentara durante operaciones prolongadas (esto se probó en las sesiones largas).
\end{itemize}

\section{Gestión de Anomalías}

Durante el proceso de pruebas, se encontraron varias anomalías que permitieron comprender que el desarrollo de software nunca es tan lineal como se espera. Todo se documentó cuidadosamente y las anomalías se fueron resolviendo una a una:

\begin{table}[ht]
    \centering
    \small
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|c|p{6cm}|c|p{4cm}|}
        \hline
        \textbf{ID} & \textbf{Descripción} & \textbf{Severidad} & \textbf{Resolución} \\
        \hline
        AN-001 & Pérdida ocasional de datos EEG en sesiones prolongadas & Media & Se implementó un búfer circular con reintento automático \\
        \hline
        AN-002 & Falsos positivos en detección de señales con baja impedancia & Baja & Se ajustó el umbral de confianza para clasificación \\
        \hline
        AN-003 & Latencia excesiva en interfaz gráfica durante visualización de señales & Media & Se optimizó el renderizado con muestreo adaptativo \\
        \hline
        AN-004 & Inconsistencia en la persistencia de configuraciones de usuario & Baja & Se refactorizó todo el sistema de almacenamiento de configuración \\
        \hline
        AN-005 & Problemas de reconexión con bombillas inteligentes tras pérdida de red & Media & Se implementó un protocolo de reconexión más resiliente \\
        \hline
    \end{tabular}
    }
    \caption{Anomalías encontradas y su resolución}
    \label{tab:anomalies}
\end{table}

Siguiendo la sección 5.8.2 de la norma, se documentaron todas las anomalías que quedaban y se evaluaron para asegurar que ninguna representaba un riesgo inaceptable para el usuario. Al final, todas las que persistían eran menores y no afectaban la funcionalidad principal.

\section{Matriz de Trazabilidad}

Una de las tareas más laboriosas pero necesarias fue desarrollar una matriz de trazabilidad que vinculara todos los requisitos del sistema con las pruebas que los verificaban. Esta matriz ayudaba a asegurar que no se había omitido probar ningún aspecto importante:


\begin{center}
\small
\begin{longtable}{|p{2.5cm}|p{5.5cm}|p{3.5cm}|p{2.5cm}|}
    \hline
    \textbf{Requisito} & \textbf{Descripción} & \textbf{Pruebas asociadas} & \textbf{Estado} \\
    \hline
    \endfirsthead
    \hline
    \textbf{Requisito} & \textbf{Descripción} & \textbf{Pruebas asociadas} & \textbf{Estado} \\
    \hline
    \endhead
    REQ-F01 & Adquisición de señales EEG desde BrainBit & UC-001, TC-001, SYS-02 & VERIFICADO \\
    \hline
    REQ-F02 & Clasificación de patrones cerebrales & UC-005, TC-003, SYS-04, SYS-05 & VERIFICADO \\
    \hline
    REQ-F03 & Control de dispositivos por pensamiento & UC-007, TC-006, SYS-06 & VERIFICADO \\
    \hline
    REQ-F04 & Visualización de estado del sistema & UC-010, TC-008, SYS-01 & VERIFICADO \\
    \hline
    REQ-F05 & Calibración del dispositivo EEG & UC-012, TC-010, SYS-03 & VERIFICADO \\
    \hline
    REQ-NF01 & Tiempo de respuesta < 3.5s & TC-020, SYS-06 & VERIFICADO \\
    \hline
    REQ-NF02 & Precisión de clasificación > 80\% & TC-021, SYS-04, SYS-05 & VERIFICADO \\
    \hline
    REQ-NF03 & Operación continua durante > 30min & TC-023, SYS-07 & VERIFICADO \\
    \hline
    \caption{Matriz de trazabilidad de requisitos y pruebas}\label{fig:traceability}
\end{longtable}
\end{center}

\newpage
\section{Conclusión de la Validación}

Después de meses de desarrollo y semanas intensas de pruebas, se puede afirmar con seguridad que la validación del prototipo Neural Analytics ha seguido rigurosamente las directrices de la norma UNE-EN 62304 para software de dispositivos médicos de Clase A. Cumplir con esta normativa fue crucial para garantizar que lo construido era seguro y efectivo.

Como requiere la sección 5.7 de la norma UNE-EN 62304, se estableció una estrategia de verificación para cada requisito del sistema. Se completaron satisfactoriamente los tres niveles de prueba necesarios —unitarias, integración y sistema— verificando el cumplimiento de todos los requisitos especificados mediante la matriz de trazabilidad presentada anteriormente.

Uno de los aspectos más destacados es el enfoque aplicado para hacer corresponder casos de uso con pruebas unitarias, como se observa en la tabla \ref{tab:use_case_tests}. Esto garantizaba que cada funcionalidad crítica del sistema estuviera adecuadamente verificada, tal como exige la sección 5.5.5 de la norma.

Esta implementación metódica de las pruebas unitarias cumple con los requisitos de las secciones 5.5.2 y 5.5.3 de la norma, que básicamente solicitaban definir criterios claros para verificar cada unidad de software y establecer procedimientos de prueba que demostraran que todo funcionaba según las especificaciones.

Los resultados obtenidos demostraron que el sistema funcionaba realmente bien:

\begin{itemize}
    \item Alta precisión en la detección de intenciones del usuario (86.8\% promedio) —mucho mejor de lo esperado inicialmente—.
    \item Tiempos de respuesta dentro de los límites establecidos (3.1s promedio).
    \item Operación estable y robusta del sistema, incluso en sesiones largas.
\end{itemize}

Las anomalías detectadas durante el proceso se documentaron cuidadosamente y se corrigieron todas, verificando que ninguna de las que quedaban representaba un riesgo inaceptable para el usuario. Esto cumplía con la sección 5.8 de la norma que exige evaluar defectos y analizar su impacto en la seguridad.

El hecho de que el software fuera Clase A según la norma permitió aplicar un nivel proporcionado de rigor en la verificación —el enfoque se centró en aspectos críticos para la funcionalidad pero reconociendo que el riesgo inherente del sistema era bajo, ya que actúa principalmente como una herramienta de monitorización sin capacidad de efectuar acciones directas sobre el paciente—.

También se adoptó un enfoque sistemático para la gestión de errores y excepciones, tal como requiere la sección 5.5.4 de la norma. Cada test unitario incluía verificaciones específicas para casos de error, como cuando no había conexión con el dispositivo o llegaban datos inválidos.

Al final, el proceso de pruebas aportó evidencia objetiva de que Neural Analytics cumple con los requisitos especificados en la normativa UNE-EN 62304:2007 y funciona correctamente en el entorno donde está previsto usarlo. Queda validado para su implementación como sistema de interfaz cerebro-computadora para el control de dispositivos domóticos mediante ondas cerebrales, lo cual genera una gran satisfacción después de todo el trabajo dedicado.

\chapter{Planificación Temporal}\label{ch:temporal_scheduling}

\section{Cronología del Desarrollo}

La organización del desarrollo del proyecto siguió una estructura metodológica dividida en fases claramente diferenciadas. Se implementó una planificación temporal que permitió el desarrollo progresivo de todos los componentes del sistema, considerando las dependencias técnicas entre módulos y los requisitos normativos específicos. La metodología adoptada facilitó el control de la complejidad técnica y garantizó el cumplimiento de los objetivos establecidos dentro del cronograma propuesto.

\subsection{Fase de Investigación (Enero 2025)}

Durante enero se establecieron las bases teóricas y técnicas del proyecto mediante una fase de investigación exhaustiva. Se realizó el análisis de las tecnologías disponibles y se evaluaron los recursos necesarios para el desarrollo:

\begin{itemize}
    \item \textbf{Estudio de arquitecturas de redes neuronales}: Se efectuó un análisis detallado de diferentes arquitecturas de aprendizaje profundo, con un enfoque particular en las redes LSTM (Long Short-Term Memory) por su adecuación para el procesamiento de secuencias temporales como las señales EEG. Se evaluaron las características específicas que hacían estas arquitecturas apropiadas para el procesamiento de datos neurofisiológicos.
    
    \item \textbf{Evaluación de dispositivos EEG}: Se compararon diferentes dispositivos disponibles en el mercado, analizando criterios como precisión, número de canales, facilidad de integración y compatibilidad con bibliotecas de software existentes. Se seleccionó el dispositivo BrainBit por ofrecer un equilibrio adecuado entre funcionalidad, costo y disponibilidad de documentación técnica.
    
    \item \textbf{Investigación de bibliotecas de adquisición de datos}: Se evaluaron múltiples bibliotecas para la captura de datos EEG, seleccionando finalmente BrainFlow debido a su compatibilidad con diversos dispositivos y la robustez de su documentación técnica, factores de alta relevancia para el desarrollo de aplicaciones médicas.
    
    \item \textbf{Estudio de normativas aplicables}: Se analizaron las regulaciones y estándares pertinentes para dispositivos médicos, prestando especial atención a la norma UNE-EN 62304 para software de dispositivos médicos. Este análisis permitió establecer los requisitos de desarrollo y documentación correspondientes.
    
    \item \textbf{Estudio de plataformas para implementación}: Se evaluaron diferentes opciones de hardware para la implementación del sistema, analizando capacidad de procesamiento en tiempo real y adecuación para aplicaciones médicas. Esta evaluación determinó los requisitos técnicos para la selección posterior del hardware.
\end{itemize}

\subsection{Adquisición de Hardware y Estructuración (Finales de Enero 2025)}

Completada la fase de investigación, se procedió a la adquisición del hardware necesario y la estructuración del proyecto. Esta fase se centró en materializar las decisiones técnicas tomadas durante la investigación y establecer la arquitectura base del sistema:

\begin{itemize}
    \item \textbf{Adquisición del dispositivo BrainBit}: Se obtuvo el dispositivo EEG seleccionado como fuente principal de datos neurofisiológicos para el proyecto. La adquisición se realizó considerando los criterios técnicos establecidos durante la fase de investigación.
    
    \item \textbf{Obtención de la Raspberry Pi 4}: Se seleccionó esta plataforma como sistema de implementación principal debido al equilibrio entre potencia de procesamiento, portabilidad y adecuación para el desarrollo de prototipos médicos.
    
    \item \textbf{Adquisición de bombillas inteligentes Tapo}: Se obtuvieron los dispositivos de control domótico necesarios para implementar las respuestas del sistema a las señales cerebrales procesadas. Esta selección se basó en la facilidad de integración y compatibilidad con los protocolos de comunicación requeridos.
    
    \item \textbf{Definición de la arquitectura del software}: Se diseñó la estructura general del proyecto adoptando una arquitectura hexagonal (puertos y adaptadores) para garantizar modularidad, testabilidad y facilidad de mantenimiento. Esta decisión arquitectónica se fundamentó en los requisitos normativos de la UNE-EN 62304.
    
    \item \textbf{Planificación de componentes del sistema}: Se definieron los módulos constituyentes del proyecto: neural\_analytics\_data para la captura de datos, neural\_analytics\_model para entrenamiento e inferencia, neural\_analytics\_core para la lógica central, y neural\_analytics\_gui para la interfaz de usuario. Esta modularización facilitó el desarrollo paralelo y la validación independiente de componentes.
\end{itemize}

\subsection{Fase de Desarrollo (Febrero - Marzo 2025)}

Durante febrero y marzo se implementaron todos los componentes del sistema siguiendo la arquitectura previamente definida. Esta fase constituyó el núcleo del desarrollo técnico, caracterizada por la implementación simultánea de múltiples módulos y su posterior integración:

\subsubsection{Desarrollo del Programa de Extracción de Datos (neural\_analytics\_data)}

Se desarrolló este módulo como primer componente del sistema, estableciendo la interfaz entre el dispositivo de adquisición y el resto del sistema. El desarrollo de este módulo presentó varios desafíos técnicos relacionados con la captura fiable de datos EEG:

\begin{itemize}
    \item \textbf{Integración con BrainFlow}: Se implementó la interfaz con la biblioteca BrainFlow para la captura de datos del dispositivo BrainBit. Se desarrolló un sistema de comunicación robusto que garantiza la adquisición continua y fiable de señales EEG.
    
    \item \textbf{Diseño de protocolos de captura}: Se desarrollaron rutinas estructuradas para la captura de datos EEG durante tareas de imaginación de colores. Se establecieron protocolos temporales precisos para garantizar la consistencia de las muestras y facilitar el posterior entrenamiento del modelo.
    
    \item \textbf{Implementación de procesamiento de señales}: Se desarrollaron funciones especializadas para filtrar y preprocesar las señales EEG en formato raw. Esta implementación abarca el estudio y aplicación de transformadas de Fourier y filtros digitales para optimizar la calidad de las señales destinadas al entrenamiento del modelo.
    
    \item \textbf{Almacenamiento y etiquetado de datos}: Se implementó un sistema automatizado para almacenar y etiquetar los datos capturados. La automatización de este proceso garantiza la consistencia y reduce errores en la gestión de datos.
\end{itemize}

\newpage
\subsubsection{Desarrollo del Programa de Entrenamiento del Modelo (neural\_analytics\_model)}

El desarrollo del módulo de entrenamiento se ejecutó en paralelo con la extracción de datos para optimizar el tiempo de desarrollo. Esta estrategia permitió la validación temprana del pipeline de entrenamiento utilizando datasets parciales, facilitando la identificación de problemas en las etapas iniciales del procesamiento de datos.

La implementación del pipeline de entrenamiento con datos iniciales reveló aspectos críticos del preprocesamiento que afectaban la calidad de la clasificación, información valiosa que solo se obtiene mediante la evaluación con datos reales.

El módulo de entrenamiento se configuró como entorno de experimentación para diversas arquitecturas y configuraciones:

\begin{itemize}
    \item \textbf{Diseño de arquitectura LSTM}: Se diseñó una red neuronal basada en capas LSTM, optimizada específicamente para la clasificación de patrones en señales EEG. El proceso incluyó la revisión exhaustiva de literatura científica y la evaluación sistemática de múltiples configuraciones para identificar los parámetros de mayor impacto en el rendimiento. Se realizaron pruebas comparativas de diferentes arquitecturas para optimizar el rendimiento con diversos conjuntos de datos.
    
    \item \textbf{Implementación en PyTorch}: Se seleccionó PyTorch como framework principal debido a su flexibilidad y facilidad de uso en comparación con TensorFlow. La implementación requirió la adaptación a la sintaxis específica del framework y el dominio del manejo de tensores para operaciones de aprendizaje profundo. Se desarrollaron rutinas optimizadas para garantizar la ejecución eficiente de los procesos de entrenamiento.
    
    \item \textbf{Rutinas de entrenamiento y validación}: Se desarrollaron procedimientos sistemáticos para entrenar el modelo de manera eficiente y validarlo con diferentes conjuntos de datos. La implementación incluye mecanismos de monitorización para garantizar la estabilidad del entrenamiento y la convergencia consistente del modelo. Se establecieron métricas de evaluación para optimizar el rendimiento y detectar variabilidades en el comportamiento del modelo durante el proceso de entrenamiento.
    
    \item \textbf{Exportación a formato ONNX}: Se implementó la conversión del modelo para su posterior utilización en Rust mediante el formato ONNX. El proceso de exportación requirió adaptaciones en la arquitectura del modelo para garantizar la compatibilidad completa entre PyTorch y ONNX. Se optimizaron las operaciones del modelo para asegurar una exportación exitosa y mantener la funcionalidad completa en el entorno de producción.
\end{itemize}

\newpage
\subsubsection{Desarrollo del Core del Sistema (neural\_analytics\_core)}

Este componente constituye el núcleo central del sistema y representa la mayor complejidad técnica del proyecto. Su desarrollo requirió una planificación detallada debido a la implementación de la arquitectura hexagonal y la integración de múltiples subsistemas.

La implementación de la arquitectura hexagonal demandó un análisis exhaustivo de los principios de diseño, incluyendo la definición precisa de puertos, adaptadores y la separación entre dominio e infraestructura.

Se estableció la arquitectura núcleo del sistema implementando los principios de diseño hexagonal para garantizar la separación entre lógica de negocio e infraestructura. Se desarrolló un sistema modular que permite la interoperabilidad eficiente entre componentes:

\begin{itemize}
    \item \textbf{Implementación de puertos y adaptadores}: Se definieron interfaces claras para todos los componentes externos (puertos) y sus implementaciones concretas (adaptadores), siguiendo estrictamente los principios de la arquitectura hexagonal. Esta implementación garantiza la flexibilidad del sistema y facilita futuras extensiones o modificaciones.
    
    \item \textbf{Desarrollo del dominio central}: Se implementó la lógica de negocio central de forma completamente independiente de las infraestructuras externas. Esta separación permite el desarrollo, testing y mantenimiento de cada componente de forma aislada, cumpliendo con los requisitos normativos de trazabilidad.
    
    \item \textbf{Sistema de eventos}: Se desarrolló un mecanismo de comunicación basado en eventos utilizando la biblioteca presage para Rust. Este sistema permite el desacoplamiento efectivo entre componentes y facilita la gestión del flujo de información a través del sistema.
    
    \item \textbf{Máquina de estados}: Se implementó una máquina de estados para gestionar el ciclo de vida de la aplicación y las transiciones entre diferentes modos operativos. Esta implementación garantiza el comportamiento predecible del sistema y facilita la gestión de estados de error y recuperación.
    
    \item \textbf{Servicio de inferencia}: Se desarrolló un servicio para la ejecución del modelo en tiempo real utilizando tract-onnx para inferencia en Rust. Esta implementación garantiza el rendimiento requerido para el procesamiento en tiempo real de señales EEG.
    
    \item \textbf{Control de dispositivos domóticos}: Se implementó la integración con dispositivos inteligentes a través de la biblioteca tapo. Esta integración permite el control remoto efectivo de dispositivos de iluminación basado en las predicciones del modelo.
\end{itemize}

\newpage
\subsubsection{Desarrollo de la Interfaz Gráfica (neural\_analytics\_gui)}

Se desarrolló la interfaz gráfica del sistema utilizando tecnologías modernas para crear una experiencia de usuario eficiente y accesible. El desarrollo se centró en proporcionar visualización en tiempo real de las señales EEG y control intuitivo del sistema:

\begin{itemize}
    \item \textbf{Diseño de interfaz con Slint}: Se utilizó el framework Slint para crear una interfaz moderna y eficiente. Esta elección tecnológica permitió el desarrollo de una interfaz responsiva con renderizado de alto rendimiento, adecuada para el procesamiento en tiempo real.
    
    \item \textbf{Visualización de señales EEG}: Se implementó la representación gráfica de las señales en tiempo real utilizando la biblioteca plotters. Esta funcionalidad permite el monitoreo continuo de la calidad de las señales y facilita la calibración del sistema.
    
    \item \textbf{Integración con el core}: Se estableció la comunicación bidireccional con el núcleo del sistema para la visualización de estados y resultados en tiempo real. Esta integración garantiza la sincronización efectiva entre el frontend y el backend del sistema.
    
    \item \textbf{Interfaz para calibración}: Se desarrollaron vistas específicas para la calibración del dispositivo y verificación de impedancias. Estas funcionalidades son críticas para garantizar la calidad de las señales EEG y la fiabilidad de las predicciones.
    
    \item \textbf{Visualización de predicciones}: Se implementó un sistema para mostrar las predicciones del modelo en tiempo real de manera clara y comprensible. La interfaz incluye indicadores de confianza y visualización de estados del sistema para facilitar la interpretación de resultados.
\end{itemize}

\subsection{Fase de Refinamiento del Modelo (Abril 2025)}

Durante abril se implementó una fase intensiva de refinamiento del modelo de aprendizaje profundo. Esta fase se caracterizó por la optimización sistemática de todos los parámetros del modelo y la ampliación significativa del dataset de entrenamiento:

\begin{itemize}
    \item \textbf{Ampliación del dataset}: Se organizaron sesiones adicionales de captura de datos EEG para aumentar significativamente tanto el tamaño como la diversidad del dataset disponible. Se incluyeron grabaciones de múltiples usuarios en diferentes condiciones temporales para mejorar la capacidad de generalización del modelo.
    
    \item \textbf{Diversificación de casos de uso}: Se expandieron los escenarios de prueba para incluir variaciones en los enfoques mentales utilizados por un único usuario durante las tareas de imaginación de colores. Esta diversificación permitió al modelo adaptarse a diferentes estrategias cognitivas individuales.
    
    \item \textbf{Reentrenamiento del modelo}: Se realizaron múltiples iteraciones de reentrenamiento del modelo LSTM utilizando los datos ampliados. Se optimizaron sistemáticamente los hiperparámetros para maximizar la precisión del modelo manteniendo el rendimiento en tiempo real.
    
    \item \textbf{Validación cruzada}: Se implementaron técnicas rigurosas de validación cruzada para verificar la consistencia del rendimiento del modelo con diferentes subconjuntos de datos. Esta metodología garantiza la fiabilidad de las métricas de rendimiento obtenidas.
    
    \item \textbf{Ajuste de umbrales de confianza}: Se refinaron los mecanismos para determinar cuándo una predicción debe clasificarse como "desconocida" en lugar de forzar una clasificación incorrecta. Esta optimización mejoró significativamente la fiabilidad percibida del sistema durante operación en condiciones de incertidumbre.
\end{itemize}

Para optimizar el tiempo requerido para refinar el modelo, se utilizó una única persona como sujeto de prueba. Esta decisión, si bien limita la generalización de los resultados, permite una validación más rápida y controlada del sistema en las fases iniciales de desarrollo. En futuras iteraciones se considera necesaria la ampliación del conjunto de datos con múltiples usuarios para mejorar la robustez del modelo.

\section{Distribución Temporal}

La distribución temporal del proyecto refleja la complejidad técnica de cada fase y las dependencias entre componentes. Los tiempos de desarrollo se organizaron de manera eficiente para optimizar el uso de recursos:

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{Fase} & \textbf{Período} & \textbf{Duración} \\
        \hline
        Investigación & Enero 2025 & 4 semanas \\
        \hline
        Adquisición y Estructuración & Finales de Enero 2025 & 1 semana \\
        \hline
        Desarrollo del Programa de Extracción & Febrero 2025 & 2 semanas \\
        \hline
        Desarrollo del Programa de Entrenamiento & Febrero 2025 & 2 semanas \\
        \hline
        Desarrollo del Core del Sistema & Febrero - Marzo 2025 & 4 semanas \\
        \hline
        Desarrollo de la Interfaz Gráfica & Marzo 2025 & 2 semanas \\
        \hline
        Pruebas Iniciales & Finales de Marzo 2025 & 2 semanas \\
        \hline
        Refinamiento del Modelo & Abril 2025 & 4 semanas \\
        \hline
    \end{tabular}
    \caption{Distribución temporal del desarrollo del proyecto Neural Analytics}
    \label{tab:temporal_distribution}
\end{table}

\newpage
\section{Diagrama de Gantt}

A continuación, se presenta la representación visual de cómo se solaparon las diferentes fases. Este tipo de diagramas permite observar la superposición temporal de las tareas, un aspecto que no resulta tan evidente al examinar únicamente las fechas:

\begin{figure}[ht]
    \centering
    \definecolor{barblue}{RGB}{153,204,254}
    \definecolor{groupblue}{RGB}{51,102,254}
    \definecolor{linkred}{RGB}{165,0,33}
    \definecolor{investigacion}{RGB}{51,102,204}
    \definecolor{adquisicion}{RGB}{60,179,113}
    \definecolor{extraccion}{RGB}{255,153,0}
    \definecolor{entrenamiento}{RGB}{255,128,0}
    \definecolor{core}{RGB}{204,0,0}
    \definecolor{interfaz}{RGB}{255,153,51}
    \definecolor{pruebas}{RGB}{153,51,153}
    \definecolor{refinamiento}{RGB}{0,204,204}
    
    \renewcommand\sfdefault{phv}
    \renewcommand\mddefault{mc}
    \renewcommand\bfdefault{bc}
    \sffamily
    \begin{ganttchart}[
        canvas/.append style={fill=none, draw=black!5, line width=.75pt},
        hgrid style/.style={draw=black!5, line width=.75pt},
        vgrid={*1{draw=black!5, line width=.75pt}},
        title/.style={draw=none, fill=none},
        title label font=\bfseries\footnotesize,
        title label node/.append style={below=4pt},
        include title in canvas=false,
        bar label font=\mdseries\small\color{black!70},
        bar label node/.append style={left=2cm},
        bar/.style={draw=none, rounded corners=1pt},
        bar height=0.7,
        y unit title=0.8cm,
        y unit chart=0.7cm,
        x unit=0.6cm,
        group left shift=0,
        group right shift=0,
        group height=.5,
        group peaks tip position=0
    ]{1}{17}
        \gantttitle[
          title label node/.append style={below left=7pt and -3pt}
        ]{\textbf{Planificación Neural Analytics 2025}}{17} \\
        \gantttitle{Enero}{4} 
        \gantttitle{Febrero}{4} 
        \gantttitle{Marzo}{5} 
        \gantttitle{Abril}{4} \\
        
        \ganttgroup[group/.style={fill=investigacion}]{Fase de Investigación}{1}{4} \\
        \ganttbar[name=invest, bar/.style={fill=investigacion!90}]{\textbf{Investigación}}{1}{4} \\[grid]
        
        \ganttgroup[group/.style={fill=adquisicion}]{Fase de Adquisición}{4}{5} \\
        \ganttbar[name=adqui, bar/.style={fill=adquisicion!90}]{\textbf{Adquisición y Estructuración}}{4}{5} \\[grid]
        
        \ganttgroup[group/.style={fill=extraccion}]{Fase de Desarrollo}{5}{15} \\
        \ganttbar[name=extract, bar/.style={fill=extraccion!90}]{\textbf{Extracción de Datos}}{5}{8} \\
        \ganttbar[name=entren, bar/.style={fill=entrenamiento!90}]{\textbf{Entrenamiento del Modelo}}{5}{8} \\
        \ganttbar[name=core, bar/.style={fill=core!90}]{\textbf{Core del Sistema}}{8}{13} \\
        \ganttbar[name=gui, bar/.style={fill=interfaz!90}]{\textbf{Interfaz Gráfica}}{13}{15} \\
        \ganttbar[name=test, bar/.style={fill=pruebas!90}]{\textbf{Pruebas Iniciales}}{13}{15} \\[grid]
        
        \ganttgroup[group/.style={fill=refinamiento}]{Fase de Refinamiento}{14}{17} \\
        \ganttbar[name=refine, bar/.style={fill=refinamiento!90}]{\textbf{Refinamiento del Modelo}}{14}{17} \\
        
        \ganttlink[link/.style={-latex, line width=1pt, black!40}]{adqui}{extract}
        \ganttlink[link/.style={-latex, line width=1pt, black!40}]{extract}{core}
        \ganttlink[link/.style={-latex, line width=1pt, black!40}]{core}{gui}
        \ganttlink[link/.style={-latex, line width=1pt, black!40}]{gui}{refine}
    \end{ganttchart}
    \caption{Diagrama de Gantt del proyecto Neural Analytics}
    \label{fig:gantt_diagram}
\end{figure}

\section{Conclusiones sobre la Planificación}

La evaluación retrospectiva de la planificación temporal del proyecto permite identificar aspectos exitosos y áreas de mejora para futuros desarrollos similares. La metodología implementada resultó adecuada para alcanzar los objetivos establecidos dentro del marco temporal propuesto.

\begin{itemize}
    \item \textbf{Duración de la fase de desarrollo core}: El desarrollo del núcleo del sistema, siguiendo estrictamente los principios de arquitectura hexagonal, requirió una inversión temporal considerable. Esta inversión se justificó por los beneficios obtenidos en términos de mantenibilidad, testabilidad y facilidad para realizar pruebas exhaustivas posteriores.
    
    \item \textbf{Paralelización de tareas}: La estructuración del desarrollo en componentes modulares desde el inicio permitió el desarrollo simultáneo de varios módulos. Esta estrategia optimizó significativamente el tiempo total de desarrollo y facilitó la gestión de la complejidad del proyecto.
    
    \item \textbf{Importancia de la fase de refinamiento}: La fase de abril presentó mayor criticidad de la inicialmente estimada. La ampliación del dataset con muestras diversas y representativas mejoró significativamente el rendimiento del modelo, validando la inversión temporal adicional requerida.
    
    \item \textbf{Iteración continua}: El enfoque iterativo constituye un aspecto fundamental, especialmente durante la etapa de refinamiento del modelo. Cada incorporación de datos genera ajustes incrementales que mejoran progresivamente el rendimiento del sistema.
    
    \item \textbf{Áreas de mejora identificadas}: Para futuros desarrollos similares, resulta conveniente ampliar significativamente la fase de pruebas con usuarios reales para obtener mayor retroalimentación sobre la usabilidad del sistema. Asimismo, se considera necesario continuar expandiendo el dataset con muestras más diversas y representativas.
\end{itemize}

La implementación de la arquitectura hexagonal, aunque inicialmente más costosa en tiempo de desarrollo, proporcionó una base sólida para cumplir efectivamente con los requisitos normativos y facilitar futuras extensiones del sistema.

La dedicación de un mes completo al refinamiento intensivo del modelo fue fundamental para alcanzar niveles de precisión adecuados para un dispositivo de uso médico. Los resultados obtenidos, que se explicarán en detalle en el capítulo \ref{ch:prototype_testing}, indican que esta fase crítica debería considerarse con mayor peso temporal en planificaciones futuras de proyectos similares.
